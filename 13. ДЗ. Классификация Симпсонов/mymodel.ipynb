{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import natsort\n",
    "from PIL import Image\n",
    "import copy\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    print(\"Using GPU\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert device==\"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.youtube.com/watch?v=Z9G1Mf6TZRs\n",
    "# быстрее, но немного теряется воспроизводимость\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark =  True \n",
    "torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# полезно посмотреть на картинки после преобразований\n",
    "# рисует тензор\n",
    "imshow = lambda x: plt.imshow(x.permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_dict = {\n",
    "    'eval': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # (imagenet normalization)\n",
    "    ]),\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1), ratio=(0.75, 1.3333333333333333), interpolation=2),\n",
    "        torchvision.transforms.RandomPerspective(distortion_scale=0.3, p=0.9, interpolation=3, fill=0),\n",
    "        torchvision.transforms.RandomAffine(degrees=30, shear=20, resample=False),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each folder inside has the name of the class\n",
    "train_path = './big_data_folder/train/'\n",
    "# folder with images that we predict classes for\n",
    "test_path = './big_data_folder/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.ImageFolder(root = train_path, transform = transforms_dict['eval'])\n",
    "data_augmented = datasets.ImageFolder(root = train_path, transform = transforms_dict['train'])\n",
    "\n",
    "n_classes = len(data.classes)\n",
    "\n",
    "label_to_name = {v: k for k, v in data.class_to_idx.items()}\n",
    "\n",
    "# получим индексы для train/val сплита\n",
    "train_indices, val_indices, _, _, = train_test_split(np.arange(len(data)), data.targets, test_size = 0.1, stratify=data.targets, random_state = 42)\n",
    "\n",
    "# Subset сохраняет порядок индексов\n",
    "train_dataloader = torch.utils.data.DataLoader(torch.utils.data.Subset(data_augmented, train_indices), batch_size = 100)\n",
    "val_dataloader = torch.utils.data.DataLoader(torch.utils.data.Subset(data, val_indices), batch_size = 100)\n",
    "final_train_dataloader = torch.utils.data.DataLoader(data_augmented, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestImageFolder(torch.utils.data.Dataset):\n",
    "    # custom dataset class\n",
    "    # basically this is an ImageFolder version for a test set\n",
    "\n",
    "    \n",
    "    def __init__(self, root, transform, ext = '.jpg'):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        files_unsorted = [i for i in os.listdir(root) if ext in i]\n",
    "        # uses smart sorting (basically goes from img0 to img9001 instead of lexicographical order)\n",
    "        self.files = natsort.natsorted(files_unsorted) \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        paths = os.path.join(self.root, self.files[idx])\n",
    "        image = Image.open(paths).convert(\"RGB\")\n",
    "        tensor_image = self.transform(image)\n",
    "        return tensor_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = TestImageFolder(test_path, transforms_dict['eval'], ext='.jpg')\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f1 = 0\n",
    "best_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, val_dataloader, num_epoch, loss_function, optimizer, scheduler, device):\n",
    "    \n",
    "    # для чекпоинта\n",
    "    global best_f1\n",
    "    global best_model\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # лосс и метрики по эпохам\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_f1 = []\n",
    "    \n",
    "    # для средних\n",
    "    train_size = float(len(train_dataloader.dataset))\n",
    "    if val_dataloader is not None:\n",
    "        val_size = float(len(val_dataloader.dataset))\n",
    "    \n",
    "    for i in range(num_epoch):\n",
    "        \n",
    "        print('epoch',i)\n",
    "        \n",
    "        # train batches\n",
    "        train_running_loss = 0\n",
    "        model.train(True)\n",
    "        for j, (inputs, labels) in enumerate(train_dataloader):\n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_running_loss += loss.item() * inputs.size(0) # лоссы усредняются по батчу, поэтому домножим на количество итемов в батче \n",
    "            \n",
    "            # чтобы не скучно было сидеть за монитором\n",
    "            if j%30 == True:\n",
    "                print('Training batch:', str(j) + ',', 'Loss:', loss.item())\n",
    "\n",
    "        train_losses.append(train_running_loss/train_size)\n",
    "          \n",
    "        # val batches\n",
    "        if val_dataloader is not None:\n",
    "            val_preds = []\n",
    "            val_true = []\n",
    "            val_running_loss = 0\n",
    "            model.train(False)\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in val_dataloader:\n",
    "\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    outputs = model(inputs)\n",
    "                    loss = loss_function(outputs, labels)\n",
    "\n",
    "                    val_running_loss += loss.item() * inputs.size(0)\n",
    "                    _, batch_preds = torch.max(outputs, axis=1)\n",
    "                    val_preds += batch_preds.tolist()\n",
    "                    val_true += labels.tolist()\n",
    "            \n",
    "            val_losses.append(val_running_loss/val_size)\n",
    "            val_f1.append(f1_score(val_true, val_preds, average='macro'))\n",
    "            \n",
    "            print('Validation loss:', val_losses[-1])\n",
    "            print('Validation f1:', val_f1[-1])\n",
    "        \n",
    "            # f1 checkpoint\n",
    "            if val_f1[-1] > best_f1:\n",
    "                best_f1 = val_f1[-1]\n",
    "                best_model = copy.deepcopy(model)       \n",
    "        \n",
    "        \n",
    "        # шаг по lr\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "    end_time = time.time()\n",
    "    \n",
    "    print('total time:',end_time-start_time)\n",
    "    print('average time per epoch:',(end_time-start_time)/num_epoch)\n",
    "    \n",
    "    return {'train_losses':train_losses,\n",
    "            'val_losses': val_losses,\n",
    "            'val_f1': val_f1,\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "# change the last fc layer to our own\n",
    "num_ftrs = model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all but 2 last layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "for param in model.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "# requires_grad is True by default for new layer\n",
    "model.fc = torch.nn.Linear(num_ftrs, n_classes)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict_frozen = train(model, final_train_dataloader, None, 5, loss_function, optimizer, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze all\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict_unfrozen = train(model, final_train_dataloader, None, 50, loss_function, optimizer, scheduler, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'mymodel.pt') # сохраним на всякий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "model.train(False)\n",
    "with torch.no_grad():\n",
    "    test_preds = []\n",
    "    for batch in test_dataloader:\n",
    "        batch = batch.to(device)\n",
    "        _, preds = model(batch).max(axis=1)\n",
    "        test_preds.append(preds.tolist())\n",
    "    # now we flatten test_preds [[batch1],[batch2]] - > [batch1,batch2]\n",
    "    test_preds = sum(test_preds,[])\n",
    "# decode labels\n",
    "test_preds = [label_to_name[label] for label in test_preds]\n",
    "submission_df = pd.DataFrame([*zip(test_data.files,test_preds,)]).rename(columns = {0:'Id', 1:'Expected'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('mysubmission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
